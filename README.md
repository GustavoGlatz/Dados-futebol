# âš½ Agenda de Futebol - Plataforma de Dados End-to-End

![Python](https://img.shields.io/badge/Python-Language-blue?logo=python&logoColor=white)
![AWS](https://img.shields.io/badge/AWS-S3,_Lambda,_ECR,_Glue,_EventBridge-orange?logo=awsorganizations&logoColor=white)
![Terraform](https://img.shields.io/badge/Terraform-Infrastructure-purple?logo=terraform&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Container-blue?logo=docker&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-red?logo=streamlit&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-Data%20Analysis-150458?logo=pandas&logoColor=white)
![PySpark](https://img.shields.io/badge/PySpark-Data_Processing-yellow?logo=apachespark&logoColor=white)

## ğŸ“Œ Sobre o Projeto

Este projeto Ã© uma **Agenda de Futebol** desenvolvido como portfÃ³lio de Engenharia de Dados. O objetivo principal Ã© consolidar e visualizar informaÃ§Ãµes sobre jogos de futebol â€” incluindo placares em tempo real, horÃ¡rios e estatÃ­sticas pÃ³s-rodada â€” atravÃ©s de uma arquitetura de dados robusta e escalÃ¡vel.

Embora o produto final seja um dashboard interativo, o foco central deste repositÃ³rio Ã© demonstrar a implementaÃ§Ã£o de um pipeline de dados **End-to-End** completo, utilizando prÃ¡ticas modernas de **Data Lakehouse**, integraÃ§Ã£o contÃ­nua (CI/CD) e Infraestrutura como CÃ³digo (IaC).

### Acesso ao Dashboard: [Agenda Futebol Hoje](https://dados-futebol.streamlit.app/) 

## ğŸ— Arquitetura da SoluÃ§Ã£o

A soluÃ§Ã£o foi arquitetada para garantir confiabilidade, escalabilidade e baixo acoplamento entre os componentes. O fluxo de dados segue o padrÃ£o de Data Lakehouse com camadas segregadas.

### Fluxo de Dados

1.  **IngestÃ£o:** Scripts Python em containers Docker consomem dados da API-Football (RapidAPI) e depositam os arquivos brutos (JSON) diretamente no Data Lake.
2.  **Armazenamento (Data Lake S3):** O armazenamento Ã© organizado na arquitetura MedalhÃ£o:
    *   **Bronze / Raw:** Dados crus conforme recebidos da API.
    *   **Silver / Cleaned:** Dados limpos, tipados e enriquecidos.
    *   **Gold / Aggregated:** Tabelas analÃ­ticas agregadas prontas para consumo de negÃ³cios.
3.  **VisualizaÃ§Ã£o:** Uma aplicaÃ§Ã£o Streamlit consome diretamente a camada Gold. OtimizaÃ§Ãµes de cache (TTL) sÃ£o aplicadas para reduzir custos de requisiÃ§Ã£o (S3 GETs) e latÃªncia.
4.  **Infraestrutura:** Todo o ambiente AWS (Buckets S3, IAM Roles, Lambda, Glue e EventBridge) Ã© provisionado via Terraform.

### Diagrama de Arquitetura

```mermaid
graph TD
    %% Atores Externos
    API["API-Football (RapidAPI)"]
    User[UsuÃ¡rio Final]

    %% CI/CD (GitHub Actions)
    subgraph CI_CD [GitHub Actions Workflows]
        %% CORREÃ‡ÃƒO AQUI: Aspas adicionadas nos dois nÃ³s abaixo
        GH_Lambda["Deploy Lambda\n(Build & Push)"]
        GH_Glue["Deploy Glue\n(Upload Scripts)"]
    end

    %% ServiÃ§os AWS e Componentes
    subgraph AWS [Environment AWS]
        
        subgraph Config [ConfiguraÃ§Ã£o & Imagens]
            SSM[SSM Parameter Store]
            ECR[Amazon ECR]
        end

        subgraph Ingestion ["IngestÃ£o (Lambda)"]
            EB[EventBridge Schedule]
            Lambda["AWS Lambda Function\n(Docker Image)"]
        end

        subgraph Transformation ["Processamento (Glue)"]
            GlueTrig[Glue Trigger]
            Glue["AWS Glue Job\n(PySpark/Python)"]
        end

        subgraph DataLake [S3 Data Lakehouse]
            Scripts[Scripts Folder]
            Bronze[(Camada Bronze\nRaw JSON)]
            Silver[(Camada Silver\nCleaned Parquet)]
            Gold[(Camada Gold\nAggregated KPIs)]
        end
    end

    subgraph Visualization [VisualizaÃ§Ã£o]
        Streamlit[Streamlit Dashboard]
    end

    %% Fluxo de Deploy (CI/CD)
    GH_Lambda -->|Build & Push Image| ECR
    GH_Lambda -.->|Update Function Code| Lambda
    GH_Glue -->|Upload .py| Scripts

    %% Fluxo de ExecuÃ§Ã£o
    EB -->|1. Cron Trigger| Lambda
    SSM -.->|API Key| Lambda
    ECR -.->|Pull Image| Lambda
    
    Lambda -->|2. GET Request| API
    API -->|3. JSON Response| Lambda
    Lambda -->|4. Write Raw| Bronze

    %% CORREÃ‡ÃƒO ANTERIOR MANTIDA
    GlueTrig -->|"5. Cron Trigger (+15min)"| Glue
    Scripts -.->|Read Script| Glue
    
    Glue -->|6. Read| Bronze
    Glue -->|7. Transform| Silver
    Glue -->|8. Aggregate| Gold

    Streamlit -->|9. Read Cache| Gold
    Streamlit -->|10. Display| User
```

## ğŸ“‚ Estrutura de DiretÃ³rios

A estrutura do projeto estÃ¡ organizada funcionalmente para separar infraestrutura, lÃ³gica de aplicaÃ§Ã£o e scripts de dados.

```bash
.
â”œâ”€â”€ dashboard/               # AplicaÃ§Ã£o de visualizaÃ§Ã£o (Streamlit)
â”‚   â”œâ”€â”€ app.py              # Ponto de entrada do Dashboard
â”‚   â””â”€â”€ requirements.txt    # DependÃªncias especÃ­ficas do dashboard
â”œâ”€â”€ Dockerfile               # DefiniÃ§Ã£o da imagem para o worker de ETL
â”œâ”€â”€ etl_script.py            # LÃ³gica de extraÃ§Ã£o e transformaÃ§Ã£o dos dados
â”œâ”€â”€ main.py                  # Orquestrador local do pipeline
â”œâ”€â”€ main.tf                  # DefiniÃ§Ã£o da infraestrutura AWS via Terraform
â”œâ”€â”€ plano.md                 # DocumentaÃ§Ã£o de planejamento e backlog
â”œâ”€â”€ pyproject.toml           # ConfiguraÃ§Ã£o do projeto e ferramentas
â”œâ”€â”€ mise.toml                # ConfiguraÃ§Ã£o de ambiente e ferramentas
â””â”€â”€ requirements.txt         # DependÃªncias do "main.py"
```

## ğŸš€ Destaques TÃ©cnicos & Boas PrÃ¡ticas

Este projeto aplica padrÃµes de mercado para garantir qualidade e manutenibilidade:

*   **Arquitetura MedalhÃ£o (Bronze/Silver/Gold):** Garante a rastreabilidade e a qualidade dos dados, permitindo reprocessamento sem perda de dados histÃ³ricos.
*   **Infrastructure as Code (IaC):** UtilizaÃ§Ã£o do Terraform para provisionamento reprodutÃ­vel e versionado da infraestrutura na AWS.
*   **Gerenciamento de DependÃªncias Moderno:** Uso do `uv` para resoluÃ§Ã£o rÃ¡pida e determinÃ­stica de pacotes Python.
*   **SeguranÃ§a e Ambientes:** ConfiguraÃ§Ã£o rigorosa de segredos utilizando variÃ¡veis de ambiente e distinÃ§Ã£o entre configuraÃ§Ãµes locais (`secrets.toml`) e de produÃ§Ã£o (Cloud Secrets).
*   **OtimizaÃ§Ã£o de Performance:** ImplementaÃ§Ã£o de estratÃ©gias de *caching* no Streamlit para minimizar chamadas dispendiosas ao S3, otimizando custos e tempo de resposta.
*   **ContainerizaÃ§Ã£o:** Uso de Docker para garantir consistÃªncia no ambiente de execuÃ§Ã£o dos scripts de ETL.
* **GitHub Actions**: CI/CD individual para cada workflow.

---
*Este projeto foi desenvolvido com fins educacionais e de demonstraÃ§Ã£o profissional.*
